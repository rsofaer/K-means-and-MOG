p;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; K-means and Gaussian Mixture estimation with EM
;; Yann LeCun, April 2004, November 2005.

(libload "libimage/image-io")
(libload "image-tiles")
(libload "gaussian")

;; choose a tile file by uncommenting 
;; one of the following lines

;; (setq *image-file* "boat.png")
;; (setq *image-file* "buildings.png")
;; (setq *image-file* "bird.png")
(setq *image-file* "airplane.png")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; make tile file and load the tiles 
;; into global variable matrix "data".
(de load-data () 
  (image-to-tiles *image-file* "tiles.mat")
  (setq data (load-matrix "tiles.mat")))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(de log2 (x) ((-double-) x) (* 1.4426950408889634 (log x)))

;; Divide every element of a vector by the sum of the elements
(de normalize (x)
  (idx-dotm0 (/ ((idx-sum x))) x x))
;; This function takes an NxM matrix "x" containing
;; N data vectors of dimension M, and a KxM matrix "m"
;; which on input contains K initial prototype vectors. 
;; The function runs the K-means algorithm on the data until 
;; convergence. Upon completion, "m" contains the K prototypes
;; calculated by K-means.
(de k-means (x m convergence)
  (let ((converged ())
        (r (int-matrix (idx-dim x 0))));; ri is what prototype xi is assigned to
    (while (not converged)
      ;; Assign vectors to prototypes
      (idx-bloop ((tile x) (assignment r))
        (assignment (closest-prototype-index tile m)))
      ;; Recompute prototypes (checking for convergence)
      ;; Compute new prototypes
      (let ((new-m (double-matrix (idx-dim m 0) (idx-dim m 1)))
            (counters (int-matrix (idx-dim m 0))))
        ;; Add vectors to prototypes while incrementing counters
        (idx-bloop ((tile x)(assignment r))
          ((select counters 0 (assignment)) (+ ((select counters 0 (assignment))) 1)); Increment counter
          ;(print (concat "assigning tile: " (str i) " to prototype: " (str (assignment)) ".  New counter: " (str (counters (assignment)))))
          (idx-add tile (select new-m 0 (assignment)) (select new-m 0 (assignment))))
        ;; Divide prototypes by counters
        (setq converged t)
        (idx-gloop ((p new-m)(old-p m)(i counters))
              (idx-dotm0 p ((double-matrix) (/ (i))) p)
            ;; Check for convergence
            (when (> ((idx-sqrdist p old-p)) convergence) (setq converged ())))
        (idx-copy new-m m)))
    m
    ))

;; Find the index in m of the vector in m closest to x
(de closest-prototype-index (x m)
    (let ((closest-index 0)
           (min-dist ((idx-sqrdist x (select m 0 0)))))
      (idx-gloop ((p m)(i))
        (let ((cur-dist ((idx-sqrdist p x))))
         (when (< cur-dist min-dist)
           (setq min-dist cur-dist)
           (setq closest-index i))))
      closest-index))

(de closest-prototype (x m)
  (select m 0 (closest-prototype-index x m)))

;; Initialize the prototype vectors for k-means
(de pick-prototypes (input-set n-prototypes)
  (let ((prototypes (double-matrix n-prototypes 
                                  (idx-dim input-set 1)))
        (indicies ()))
    (while (< (length indicies) n-prototypes)
      (let ((new-i (int (rand 0 (idx-dim input-set 0)))))
        (when (not (member new-i indicies))
          (setq indicies (nconc1 indicies new-i)))))
    (idx-gloop ((v prototypes)(c))
       (let ((i (nth c indicies)))
         (idx-copy (select input-set 0 i) v) 
         ))
    prototypes))

;; Calculate the mean-squared error 
;; for a dataset (x)
;; and a set of prototypes (m)
(de mean-squared-error (x m)
  (let ((total-error 0))
    (idx-bloop ((tile x))
      (setq total-error 
        (+ total-error ((idx-sqrdist tile (closest-prototype tile m))))))
    (/ total-error (idx-dim x 0))))

(de compressed-tiles (input n-prototypes)
  (let ((prototypes (pick-prototypes input n-prototypes))
        (output (idx-copy input)))
        (k-means input prototypes 0.00001)
        (idx-bloop ((x output))
          (idx-copy (closest-prototype x prototypes) x))
        output
    ))

(de compressed-image (input n-prototypes)
  (let ((image (ubyte-matrix 600 800)))
    (tiles-to-image (compressed-tiles input n-prototypes) image)
    image
    ))

(de required-bits (input prototypes)
  (let ((histogram (double-matrix (idx-dim prototypes 0)))
        (entropy 0))
    (idx-bloop ((x input))
      (let ((k (closest-prototype-index x prototypes)))
         ((select histogram 0 k) (+ 1 ((select histogram 0 k))))))
    (idx-dotm0 histogram ((double-matrix)(/ (idx-dim input 0))) histogram)
    (idx-bloop ((hk histogram))
      (setq entropy (- entropy (* (hk) (log2 (hk))))))
    (* entropy (idx-dim input 0))
    ))
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; create an array of k Gaussians of dimension n
(de make-array-of-gaussians (k n)
  (let ((g (array k)))
    (idx-bloop ((g g)) (g (new gaussian n)))
    g))


;; This function run EM on a gaussian mixture model
;; with K components.  "x" is an NxM matrix "x" containing
;; N data vectors of dimension M, "g" is an array of Gaussian 
;; objects, and "w" is K-dimensional vector containing
;; the initial mixture weights. On output, "g", and "w" will 
;; contain the updated Gaussians, and mixture weights of the
;; mixture of gaussians. The function returns the
;; negative log-likelihood of the data given the model.
(de mog-em (x g w)
  (let* ((k (idx-dim g 0))
	 (n (idx-dim x 0))
	 (r (matrix n k))
	 (neg-log-likelihood 0)
	 (converged t))
    (while (not converged)
      (mog-e x g w r)
      (mog-m x g w r)
      (setq neg-log-likelihood (mog-nll x g w))
      (setq converged (error "you must implement convergence calculation")))
    neg-log-likelihood))


;; This is the E-step of EM
;; "r" is the matrix of responsabilities.
;; Set the elements of the responsibility matrix
;; (r n k (the responsibility of distribution k for data point n))
(de mog-e (x g w r) 
  (idx-bloop ((data-row x) (resp-row r)); row is the responsibilities corresponding to one data point
    (idx-bloop ((cell resp-row)(distribution g)(weight w))
      ;; Set cell to the responsibility of distribution for row
      (cell (* weight (==> distribution evaluate data-row))))
    (normalize resp-row)))

;; This is the M-step of EM
;; "r" is the matrix of responsabilities.
(de mog-m (x g w r) 
  (mog-means x g r)
  (mog-covariances x g r)
  (mog-weights w r))

(de mog-means (x g r)
  (idx-gloop ((distribution g)(i))
    ;; Set the mean of distribution to the sum of the rows of x, weighted by the responsibility
    (let ((g-resps (select r 1 i)); select one column of responsibilities
          (mean (double-matrix (idx-dim x 1)))) ; start with a mean of zeros
      (idx-bloop ((row x) (weight g-resps)) ; iterate through the data and the resps
          (idx-add mean (idx-dotm0 row weight) mean)) ; add the data weighted by resp
      )))

(de mog-covariances (x g r)
  (idx-bloop ((dist g))
    (==> g learn x r)))

(de mog-weights (w r)
  (idx-bloop ((weight w) (feature (transpose x)))
      (weight (idx-sum feature)))
  (normalize w))

;; Return the negative log-likelihood of the data in x
;; given the Gaussian mixture models in g and the
;; weights w.
(de mog-nll (x g w)
  (error "you must implement this function")
  ())

(load-data)

;(setq prototypes (pick-prototypes data 7))
;(k-means data prototypes 0.00001)

;; Question 1.2
;(setq prototype-list (list 2 4 8 64 256))
;
;(setq error-results 
;  (all ((n prototype-list)) 
;    (let ((prototypes (pick-prototypes data n)))
;          (k-means data prototypes 0.00001)
;          (mean-squared-error data prototypes)
;          )))
;(each ((e error-results)(n prototype-list))
;  (print (concat "K-means with " (str n) " prototypes resulted in an error of " (str e) ".")))
;
;(writing "kmeans-errors.bin" (bwrite error-results))

;; Question 1.3
;(image-write-ubim "reconstructed.png" (compressed-image data 256))

;; Question 1.4
;(setq prototypes (pick-prototypes data 8))
;(k-means data prototypes 0.00001)
;(print (concat (str (required-bits data prototypes)) " bits will be required to write the image."))

